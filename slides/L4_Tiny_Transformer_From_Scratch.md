# L4 Tiny Transformer From Scratch

- Goal: Implement self-attention and a small Transformer block
- Hands-on: character-level tiny Transformer trained on theme text
- Key concept: attention lets tokens look at relevant context

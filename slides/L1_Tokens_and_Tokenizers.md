# L1 Tokens and Tokenizers

- Goal: Understand bytes → tokens → BPE merges
- Hands-on: Build a tiny BPE tokenizer; edit corpus and re-train merges
- Key concept: subword tokens compress frequent patterns
